1. Provider Validation
Purpose: Only allow specific providers in root module Allowed Providers: aws, azurerm, google, kubernetes, helm, random, local, null, tls, template

Sample Output:

=== Provider Validation Started ===
ğŸ“‹ Found 5 provider configurations
âœ… Allowed providers: ["aws" "azurerm" "google" "kubernetes" "helm" "random" "local" "null" "tls" "template"]

=== Checking Root Provider Compliance ===
Checking root provider: aws
  âœ… Allowed provider in root module

Checking root provider: kubernetes
  âœ… Allowed provider in root module

Checking root provider: datadog
  âŒ VIOLATION: Disallowed provider 'datadog' found in root module: datadog
     Allowed providers: ["aws" "azurerm" "google" "kubernetes" "helm" "random" "local" "null" "tls" "template"]

ğŸš« === Provider Validation Failed ===
2. Module Provider Source Validation
Purpose: Ensure all modules use rbikash7758 organization sources, not public registry Allowed Sources: git@github.com:rbikash7758/terraform-*

Sample Output:

=== Module Provider Source Validation Started ===
ğŸ“‹ Checking 3 modules for provider source compliance

Checking module: ec2_instance
  âœ… Module uses rbikash7758 organization source

Checking module: public_registry_vpc
  âŒ VIOLATION: Module public_registry_vpc uses public registry source: terraform-aws-modules/vpc/aws
     Expected: git@github.com:rbikash7758/terraform-*

ğŸš« === Module Provider Source Validation Failed ===
3. Module Source Validation
Purpose: Enforce proper Git source format with versioning Required Format: git@github.com:rbikash7758/terraform-*.git?ref=v#.#.#-ga

Sample Output:

=== Module Source Validation Started ===
ğŸ“‹ Found 3 modules

Processing module: ec2_instance
  âœ… Module source is valid

Processing module: public_s3_module
  âŒ Module public_s3_module: Invalid source format (missing ?ref=)

ğŸš« === Module Source Validation Failed ===
4. Resource Location Validation
Purpose: Prevent resources from being defined in root module (must use modules) Rule: All managed resources must be in modules, not root

Sample Output:

=== Resource Location Validation Started ===

ğŸš« === Resource Validation Failed ===
Found 2 resources in root module:
  âŒ aws_instance.direct_ec2
  âŒ aws_vpc.direct_vpc
5. Data Block Validation
Purpose: Prohibit all data blocks in Terraform configuration Rule: No data blocks allowed anywhere

Sample Output:

=== Data Block Validation Started ===
ğŸ“‹ Found 4 data blocks in configuration

=== Data Block Analysis ===
âŒ VIOLATION: Data block not allowed: data.aws_ami.ubuntu (type: aws_ami)
   Data blocks are prohibited in this configuration
âŒ VIOLATION: Data block not allowed: data.aws_availability_zones.available (type: aws_availability_zones)
   Data blocks are prohibited in this configuration

ğŸš« === Data Block Validation Failed ===
6. Instance Compliance Validation
Purpose: Enforce allowed EC2 instance types and mandatory tags Allowed Instance Types: t2.micro, t2.small, t2.medium Mandatory Tags: Name

Sample Output:

=== Instance Compliance Validation Started ===
ğŸ“‹ Found 2 EC2 instances to validate

=== Instance Type Analysis ===
Instance: aws_instance.direct_ec2
  Type: t2.micro
  âœ… Instance type is allowed
  âœ… Required tag 'Name' is present

Instance: module.ec2_instance.aws_instance.ec2_instance
  Type: c5.xlarge
  âŒ VIOLATION: Instance uses disallowed type: c5.xlarge
  âœ… Allowed types: ["t2.micro" "t2.small" "t2.medium"]

ğŸš« === Instance Type Violations ===
âŒ Instance module.ec2_instance.aws_instance.ec2_instance uses disallowed type: c5.xlarge
Final Validation Results Summary
Sample Complete Output:

ğŸ” Starting Consolidated Policy Validation

=== Final Validation Results ===
Provider Validation: âŒ Failed
Module Provider Source Validation: âŒ Failed  
Module Source Validation: âŒ Failed
Resource Location Validation: âŒ Failed
Data Block Validation: âŒ Failed
Instance Compliance Validation: âŒ Failed

Main Rule: âŒ FAILED


sentinel test vs sentinel apply - Key Differences
ğŸ§ª sentinel test
Purpose: Unit testing and development validation

What it does:

Runs mock data against your policy
Tests your policy logic with predefined scenarios
Validates that your policy behaves correctly under different conditions
Uses fake/simulated Terraform plan data
No real infrastructure is involved
When to use:

During policy development
Before deploying policies to production
Continuous Integration (CI/CD) pipelines
Regression testing after policy changes
Example:

sentinel test -run="pass" enforce-policy-consolidated.sentinel
# Uses mock-tfplan-pass.sentinel (fake data)
# Tests if policy correctly allows compliant configurations
ğŸš€ sentinel apply
Purpose: Real-world policy enforcement

What it does:

Runs against actual Terraform plan data
Evaluates real infrastructure changes
Makes actual pass/fail decisions for deployments
Uses live tfplan.json from terraform plan
Blocks or allows real infrastructure changes
When to use:

In production Terraform workflows
As part of Terraform Cloud/Enterprise policy sets
Before terraform apply to validate real changes
In CI/CD pipelines with actual infrastructure
Example:

sentinel apply enforce-policy-consolidated.sentinel
# Uses actual tfplan.json from terraform plan
# Makes real decisions about infrastructure deployment


ğŸ­ What is Mock Testing?
Think of mock testing like rehearsing a play with fake props instead of real ones:

Real Performance (sentinel apply) = Using real stage, real props, real audience
Rehearsal (sentinel test) = Using fake stage, cardboard props, no audience
ğŸ“ Your Test Structure
sentinel-policies/
â”œâ”€â”€ enforce-policy-consolidated.sentinel    # The actual policy (like a script)
â””â”€â”€ test/
    â””â”€â”€ enforce-policy-consolidated/
        â”œâ”€â”€ pass.hcl                        # Test that should PASS
        â”œâ”€â”€ fail.hcl                        # Test that should FAIL  
        â”œâ”€â”€ mock-tfplan-pass.sentinel       # Fake "good" data
        â””â”€â”€ mock-tfplan-fail.sentinel       # Fake "bad" data
ğŸ”„ How It Works Step by Step
Step 1: Test Configuration Files (.hcl)
pass.hcl tells Sentinel:

mock "tfplan/v2" {
  module {
    source = "./mock-tfplan-pass.sentinel"  # Use this fake data
  }
}

test {
  rules = {
    main = true    # I expect the policy to PASS (return true)
  }
}
fail.hcl tells Sentinel:

mock "tfplan/v2" {
  module {
    source = "./mock-tfplan-fail.sentinel"  # Use this fake data
  }
}

test {
  rules = {
    main = false   # I expect the policy to FAIL (return false)
  }
}
Step 2: Mock Data Files (.sentinel)
mock-tfplan-pass.sentinel contains fake "good" data:

raw = {
  "configuration": {
    "provider_config": {
      "aws": {                    # âœ… Allowed provider
        "name": "aws"
      },
      "kubernetes": {             # âœ… Allowed provider  
        "name": "kubernetes"
      }
    }
  }
}
mock-tfplan-fail.sentinel contains fake "bad" data:

raw = {
  "configuration": {
    "provider_config": {
      "datadog": {                # âŒ Disallowed provider
        "name": "datadog"
      },
      "newrelic": {               # âŒ Disallowed provider
        "name": "newrelic"  
      }
    }
  }
}
Step 3: What Happens When You Run Tests
sentinel test enforce-policy-consolidated.sentinel
For pass.hcl:

ğŸ“¥ Sentinel loads fake "good" data from mock-tfplan-pass.sentinel
ğŸ”„ Runs your policy against this fake data
âœ… Policy sees only aws and kubernetes (allowed providers)
âœ… Policy returns true (passes)
âœ… Test expects main = true, gets true â†’ TEST PASSES
For fail.hcl:

ğŸ“¥ Sentinel loads fake "bad" data from mock-tfplan-fail.sentinel
ğŸ”„ Runs your policy against this fake data
âŒ Policy sees datadog and newrelic (disallowed providers)
âŒ Policy returns false (fails)
âœ… Test expects main = false, gets false â†’ TEST PASSES
ğŸ¯ Key Concepts
Mock Data = Fake Terraform Plan
Real Terraform Plan          Mock Data
==================          =========
terraform plan               mock-tfplan-pass.sentinel
â†“                           â†“
tfplan.json                 Fake JSON structure
â†“                           â†“
sentinel apply              sentinel test
Test Logic
Test Name: "pass"
Expected: Policy should PASS (main = true)
Mock Data: Only good providers (aws, kubernetes)
Result: Policy passes âœ… â†’ Test passes âœ…

Test Name: "fail"  
Expected: Policy should FAIL (main = false)
Mock Data: Bad providers (datadog, newrelic)
Result: Policy fails âŒ â†’ Test passes âœ…
ğŸ” Your Test Results Explained
PASS - enforce-policy-consolidated.sentinel
  PASS - test/enforce-policy-consolidated/fail.hcl
  PASS - test/enforce-policy-consolidated/pass.hcl
1 tests completed in 11.087125ms
What this means:

âœ… Overall: All tests passed
âœ… fail.hcl: Policy correctly rejected bad providers (datadog, newrelic)
âœ… pass.hcl: Policy correctly accepted good providers (aws, kubernetes)
âš¡ Speed: Tests ran in 11ms (super fast because it's fake data)
ğŸ­ Real World Analogy
Mock Testing is like:

ğŸ¬ Movie rehearsal with cardboard props vs real movie set
ğŸ³ Cooking practice with play food vs real ingredients
ğŸš— Driving simulator vs real car on real road
Benefits:

âœ… Safe: No real infrastructure affected
âœ… Fast: No real Terraform planning needed
âœ… Controlled: You create exact scenarios to test
âœ… Repeatable: Same fake data every time
ğŸ’¡ Why This is Powerful
Test Edge Cases: Create fake data for rare scenarios
Test Failures: Safely test what happens when things go wrong
Fast Feedback: Know if your policy works before deploying
Regression Testing: Ensure changes don't break existing logic
Example Use Cases:

# Test what happens with 50 disallowed providers
# Test what happens with no providers at all  
# Test what happens with malformed provider config
# Test what happens with mixed good/bad providers
This way, you can be confident your policy works correctly before it starts blocking real infrastructure deployments!